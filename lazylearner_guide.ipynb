{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LazyLearner\n",
    "\n",
    "LazyLearner implements three common transfer learning techniques: Integrated Feature Extraction, Standalone Feature Extraction and Fine-tuning. All three approaches are following the same structure:\n",
    "\n",
    "### 1. Create an instance of the searcher\n",
    "Give as arguments\n",
    "* a list of strings with the pretrained models you want to test,\n",
    "* the numer of classes of the dataset, \n",
    "* the shape of the input the model will receive  \n",
    "* optionally, a custom top model (if None, a simple 1 Dense, 1 Dropout network is used) and\n",
    "* in ConvBaseSearchWI only, the number of layers that should be fine tuned.\n",
    "\n",
    "\n",
    "### 2. Compile the models\n",
    "Give as arguments\n",
    "* optimizer,\n",
    "* loss function and \n",
    "* list of metrics.\n",
    "\n",
    "\n",
    "### 3. Fit the models\n",
    "Give as arguments\n",
    "* train set generator object \n",
    "* steps per epoch\n",
    "* number of epochs\n",
    "* optionally, validation data and validation steps per epoch\n",
    "* in ConvBaseSearchSFE only, the batch size (in the other classes the batch size of the generator is used).\n",
    "\n",
    "\n",
    "### 4. Evaluate models\n",
    "Give as argument\n",
    "* test set generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#https://stackoverflow.com/questions/42654961/creating-pandas-dataframe-from-os\n",
    "res = []\n",
    "path = 'C:\\\\Users\\\\Michael\\\\Desktop\\\\Master\\\\Deep Learning\\\\Project\\\\011_Fotos\\\\'\n",
    "#path = 'E:\\\\Dados\\\\FLH HOLIDAY RENTALS\\\\011_Fotos\\\\'\n",
    "for root, dirs, files in os.walk(path, topdown=True):\n",
    "    if len(files) > 0:\n",
    "        res.extend(list(zip([root]*len(files), files)))\n",
    "\n",
    "df = pd.DataFrame(res, columns=['Path', 'File_Name'])\n",
    "\n",
    "\n",
    "df = df[df['File_Name'] != 'Thumbs.db']\n",
    "#df['ClientId'] = df.Path.apply(lambda x: int(x.split(\"\\\\\")[-1]))\n",
    "#df = df[df['ClientId'] < 10000]\n",
    "\n",
    "df['Full_Path'] = df[\"Path\"] + '\\\\' + df[\"File_Name\"]\n",
    "df['Cat'] = df.File_Name.apply(lambda x: x.split(\".\")[0].split(\"_\")[-1])\n",
    "\n",
    "classes = ['1','3','4']\n",
    "df = df[df.Cat.isin(classes)]\n",
    "df_total = df\n",
    "numOfSamplesCat = 400\n",
    "\n",
    "df = pd.DataFrame(columns=df_total.columns)\n",
    "# Get only n pics of each class\n",
    "for cl in classes:\n",
    "    df_class = shuffle(df_total[df_total['Cat'] == cl]).iloc[:numOfSamplesCat, :]\n",
    "    df = df.append(df_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Feature Extraction\n",
    "The convolutional base of the pretrained model is plugged to a custom top model. All layers in the convolutional base are frozen, only the custom top model will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 960 validated image filenames belonging to 3 classes.\nFound 240 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = train_datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazylearner import ConvBaseSearchIFE\n",
    "classifier = ConvBaseSearchIFE(['vgg16','vgg19'], len(classes), input_shape=(64,64,3), top_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting  vgg16\nEpoch 1/1\n16/16 [==============================] - 412s 26s/step - loss: 1.4013 - accuracy: 0.4658 - val_loss: 0.7787 - val_accuracy: 0.5375\nScore on val set:  0.5375000238418579 \n\nFitting  vgg19\nEpoch 1/1\n16/16 [==============================] - 311s 19s/step - loss: 1.1952 - accuracy: 0.5049 - val_loss: 0.7618 - val_accuracy: 0.6208\nScore on val set:  0.6208333373069763 \n\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs=1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [0.8301326632499695, 0.5833333134651184],\n 'vgg19': [0.8300464153289795, 0.6458333134651184]}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standalone Feature Extraction\n",
    "The feature map produced by the convolutional base of the pretrained model is extracted first and then they are used as the input for tha custom top model. \n",
    "\n",
    "_Faster than integrated feature extraction, but data augmentation techniques cannot be applied to the input data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 960 validated image filenames belonging to 3 classes.\nFound 240 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 50\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazylearner import ConvBaseSearchSFE\n",
    "classifier = ConvBaseSearchSFE(['vgg16', 'vgg19'], len(classes), input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting Features...\nSuccessfully extraced features from  vgg16\nSuccessfully extraced features from  vgg19\n\nFit top model with feature maps\nFitting  vgg16\nTrain on 960 samples, validate on 240 samples\nEpoch 1/1\n960/960 [==============================] - 2s 2ms/step - loss: 1.1224 - accuracy: 0.5312 - val_loss: 0.9969 - val_accuracy: 0.5583\nScore on val set:  0.5583333373069763\nFitting  vgg19\nTrain on 960 samples, validate on 240 samples\nEpoch 1/1\n960/960 [==============================] - 1s 1ms/step - loss: 1.0053 - accuracy: 0.5479 - val_loss: 0.7916 - val_accuracy: 0.6750\nScore on val set:  0.675000011920929\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs = 1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "240/240 [==============================] - 0s 121us/step\n240/240 [==============================] - 0s 91us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [0.7838989655176799, 0.6875],\n 'vgg19': [0.7915910482406616, 0.675000011920929]}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning\n",
    "The convolutional base of the pretrained model is plugged to a custom top model. The last n_trainable layers of the convolutional base are trained jointly with the custom top model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 960 validated image filenames belonging to 3 classes.\nFound 240 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = train_datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazylearner import ConvBaseSearchFT\n",
    "classifier = ConvBaseSearchFT(['vgg16', 'vgg19'], len(classes), input_shape=(64,64,3), n_trainable=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initial training\nFitting  vgg16\nEpoch 1/1\n20/20 [==============================] - 402s 20s/step - loss: 1.2734 - accuracy: 0.4677 - val_loss: 0.8562 - val_accuracy: 0.6375\nScore on val set:  0.637499988079071 \n\nFitting  vgg19\nEpoch 1/1\n20/20 [==============================] - 384s 19s/step - loss: 1.2429 - accuracy: 0.4708 - val_loss: 0.8988 - val_accuracy: 0.5667\nScore on val set:  0.5666666626930237 \n\nFine tuning of last 5 layers\nFitting  vgg16\nEpoch 1/1\n20/20 [==============================] - 388s 19s/step - loss: 0.8278 - accuracy: 0.6313 - val_loss: 0.7104 - val_accuracy: 0.7208\nScore on val set:  0.7208333611488342 \n\nFitting  vgg19\nEpoch 1/1\n20/20 [==============================] - 376s 19s/step - loss: 0.8862 - accuracy: 0.6073 - val_loss: 0.7276 - val_accuracy: 0.7167\nScore on val set:  0.7166666388511658 \n\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs = 1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [0.7389445304870605, 0.6833333373069763],\n 'vgg19': [0.6807215809822083, 0.6875]}"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitmichaelvirtualenv8c63a04aa4df46b1aed515199121a56c",
   "display_name": "Python 3.7.4 64-bit ('Michael': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}