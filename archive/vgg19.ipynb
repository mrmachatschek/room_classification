{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_dataframe(folder_dir, test_size=0.2, skip_classes=None):\n",
    "    #https://stackoverflow.com/questions/42654961/creating-pandas-dataframe-from-os\n",
    "    res = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_dir, topdown=True):\n",
    "        if len(files) > 0:\n",
    "            res.extend(list(zip([root]*len(files), files)))\n",
    "\n",
    "    df = pd.DataFrame(res, columns=['Path', 'File_Name'])\n",
    "\n",
    "    df = df[df['File_Name'] != 'Thumbs.db']\n",
    "    df['ClientId'] = df.Path.apply(lambda x: int(x.split(\"\\\\\")[-1]))\n",
    "    df = df[df['ClientId'] < 10000]\n",
    "\n",
    "    df['Full_Path'] = df[\"Path\"] + '\\\\' + df[\"File_Name\"]\n",
    "    df['Cat'] = df.File_Name.apply(lambda x: x.split(\".\")[0].split(\"_\")[-1])\n",
    "\n",
    "    df = df[df['Cat'].map(df['Cat'].value_counts()) > 1]\n",
    "\n",
    "    if skip_classes != None:\n",
    "        df = df[df.Cat.notin(skip_classes)]\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=1, stratify=df.Cat.values)\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = prepare_dataframe(folder_dir = 'C:\\\\Users\\\\Michael\\\\Feels Like Home\\\\Francisco Cruz - Fotos_DL\\\\011_Fotos\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VGG19 for feature extraction\n",
    "Freeze the convolutional base and only train the densely connected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nModel: \"vgg19\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 150, 150, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n=================================================================\nTotal params: 20,024,384\nTrainable params: 20,024,384\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from keras.applications import VGG19\n",
    "\n",
    "conv_base = VGG19(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "conv_base.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Option \n",
    "# Run the conv_base once with all the images to obtain the features, save the results as a numpy array and then use it as the input to a standalone, densely conncected classifier\n",
    "# Faster option\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Function adapted from Deep Learning with Python (Francois Chollet, 2018)\n",
    "def extract_features(df, sample_count, batch_size):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,6))\n",
    "    generator = datagen.flow_from_dataframe(dataframe=df.iloc[0:sample_count,:], directory=None, x_col='Full_Path', y_col='Cat',\n",
    "                                            target_size=(150, 150), batch_size=batch_size, class_mode='categorical')\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generator: \n",
    "        print(\"Batch:\", i)\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 10 validated image filenames belonging to 6 classes.\nBatch: 0\n"
    }
   ],
   "source": [
    "# Extract features \n",
    "\n",
    "train_size = 10\n",
    "train_features, train_labels = extract_features(df_train, train_size, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10, 4, 4, 512)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2200 validated image filenames belonging to 14 classes.\nBatch: 0\nBatch: 1\nBatch: 2\nBatch: 3\nBatch: 4\nBatch: 5\nBatch: 6\nBatch: 7\nBatch: 8\nBatch: 9\nBatch: 10\nBatch: 11\nBatch: 12\nBatch: 13\nBatch: 14\nBatch: 15\nBatch: 16\nBatch: 17\nBatch: 18\nBatch: 19\nBatch: 20\nBatch: 21\n"
    }
   ],
   "source": [
    "test_size = 2200\n",
    "test_features, test_labels = extract_features(df_test, test_size, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numpy arrays as .npy \n",
    "np.save(\"test_features.npy\", test_features)\n",
    "np.save(\"test_labels.npy\", test_labels)\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.load(\"test_features.npy\")\n",
    "test_labels = np.load(\"test_labels.npy\")\n",
    "train_features = np.load(\"train_features.npy\")\n",
    "train_labels = np.load(\"train_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "train_input = np.reshape(train_features, (train_size, 4 * 4 * 512))\n",
    "test_input = np.reshape(test_features, (test_size, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n9000/9000 [==============================] - 20s 2ms/step - loss: 2.3989 - accuracy: 0.2446\nEpoch 2/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 2.0581 - accuracy: 0.3434\nEpoch 3/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.8770 - accuracy: 0.4013\nEpoch 4/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.7531 - accuracy: 0.4426\nEpoch 5/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.6453 - accuracy: 0.4679\nEpoch 6/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.5676 - accuracy: 0.4964\nEpoch 7/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.5139 - accuracy: 0.5094\nEpoch 8/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.4513 - accuracy: 0.5332\nEpoch 9/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.3997 - accuracy: 0.5467\nEpoch 10/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.3741 - accuracy: 0.5526\nEpoch 11/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.3374 - accuracy: 0.5648\nEpoch 12/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.2941 - accuracy: 0.5736\nEpoch 13/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.2639 - accuracy: 0.5871\nEpoch 14/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.2298 - accuracy: 0.5918\nEpoch 15/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.2126 - accuracy: 0.6037\nEpoch 16/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.1731 - accuracy: 0.6146\nEpoch 17/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.1513 - accuracy: 0.6202\nEpoch 18/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.1268 - accuracy: 0.6269\nEpoch 19/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.1074 - accuracy: 0.6353\nEpoch 20/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.0921 - accuracy: 0.6374\nEpoch 21/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 1.0682 - accuracy: 0.6444\nEpoch 22/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 1.0536 - accuracy: 0.6513\nEpoch 23/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 1.0350 - accuracy: 0.6573\nEpoch 24/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 1.0126 - accuracy: 0.6677\nEpoch 25/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 1.0003 - accuracy: 0.6712\nEpoch 26/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.9771 - accuracy: 0.6752\nEpoch 27/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.9575 - accuracy: 0.6882\nEpoch 28/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.9456 - accuracy: 0.6812\nEpoch 29/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.9255 - accuracy: 0.6926\nEpoch 30/100\n9000/9000 [==============================] - 17s 2ms/step - loss: 0.9078 - accuracy: 0.6982\nEpoch 31/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.8953 - accuracy: 0.7042\nEpoch 32/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.8856 - accuracy: 0.7017\nEpoch 33/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.8697 - accuracy: 0.7131\nEpoch 34/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.8540 - accuracy: 0.7159\nEpoch 35/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.8446 - accuracy: 0.7191\nEpoch 36/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.8251 - accuracy: 0.7239\nEpoch 37/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.8159 - accuracy: 0.7274\nEpoch 38/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.8072 - accuracy: 0.7379\nEpoch 39/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7938 - accuracy: 0.7369\nEpoch 40/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7746 - accuracy: 0.7423\nEpoch 41/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7692 - accuracy: 0.7463\nEpoch 42/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7526 - accuracy: 0.7469\nEpoch 43/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7500 - accuracy: 0.7509\nEpoch 44/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7268 - accuracy: 0.7576\nEpoch 45/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.7056 - accuracy: 0.7649\nEpoch 46/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6990 - accuracy: 0.7719\nEpoch 47/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6824 - accuracy: 0.7723\nEpoch 48/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6729 - accuracy: 0.7769\nEpoch 49/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6649 - accuracy: 0.7804\nEpoch 50/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6520 - accuracy: 0.7863\nEpoch 51/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6467 - accuracy: 0.7874\nEpoch 52/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6352 - accuracy: 0.7901\nEpoch 53/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6235 - accuracy: 0.7974\nEpoch 54/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.6174 - accuracy: 0.7991\nEpoch 55/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.6024 - accuracy: 0.8018\nEpoch 56/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5800 - accuracy: 0.8129\nEpoch 57/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5827 - accuracy: 0.8097\nEpoch 58/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5801 - accuracy: 0.8140\nEpoch 59/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5614 - accuracy: 0.8164\nEpoch 60/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5560 - accuracy: 0.8182\nEpoch 61/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.5434 - accuracy: 0.8213\nEpoch 62/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.5345 - accuracy: 0.8238\nEpoch 63/100\n9000/9000 [==============================] - 19s 2ms/step - loss: 0.5162 - accuracy: 0.8318\nEpoch 64/100\n9000/9000 [==============================] - 19s 2ms/step - loss: 0.5115 - accuracy: 0.8354\nEpoch 65/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.5121 - accuracy: 0.8320\nEpoch 66/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4897 - accuracy: 0.8409\nEpoch 67/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4806 - accuracy: 0.8469\nEpoch 68/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4815 - accuracy: 0.8442\nEpoch 69/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4738 - accuracy: 0.8486\nEpoch 70/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4627 - accuracy: 0.8536\nEpoch 71/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4580 - accuracy: 0.8529\nEpoch 72/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4429 - accuracy: 0.8614\nEpoch 73/100\n9000/9000 [==============================] - 17s 2ms/step - loss: 0.4326 - accuracy: 0.8651\nEpoch 74/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4295 - accuracy: 0.8664\nEpoch 75/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4177 - accuracy: 0.8679\nEpoch 76/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4117 - accuracy: 0.8728\nEpoch 77/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4120 - accuracy: 0.8717\nEpoch 78/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.4011 - accuracy: 0.8757\nEpoch 79/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.3999 - accuracy: 0.8719\nEpoch 80/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.3847 - accuracy: 0.8786\nEpoch 81/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.3736 - accuracy: 0.8806\nEpoch 82/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.3742 - accuracy: 0.8829\nEpoch 83/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3690 - accuracy: 0.8846\nEpoch 84/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3636 - accuracy: 0.8857\nEpoch 85/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3568 - accuracy: 0.8900\nEpoch 86/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3420 - accuracy: 0.8967\nEpoch 87/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3397 - accuracy: 0.8957\nEpoch 88/100\n9000/9000 [==============================] - 16s 2ms/step - loss: 0.3417 - accuracy: 0.8923\nEpoch 89/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3246 - accuracy: 0.9019\nEpoch 90/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3258 - accuracy: 0.9020\nEpoch 91/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3080 - accuracy: 0.9058\nEpoch 92/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3111 - accuracy: 0.9066\nEpoch 93/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.3075 - accuracy: 0.9096\nEpoch 94/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2994 - accuracy: 0.9110\nEpoch 95/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2921 - accuracy: 0.9131\nEpoch 96/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2937 - accuracy: 0.9103\nEpoch 97/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2805 - accuracy: 0.9123\nEpoch 98/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2826 - accuracy: 0.9157\nEpoch 99/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2643 - accuracy: 0.9213\nEpoch 100/100\n9000/9000 [==============================] - 15s 2ms/step - loss: 0.2700 - accuracy: 0.9203\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation=\"relu\", input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(14, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(train_input, train_labels, epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2200/2200 [==============================] - 2s 749us/step\naccuracy 68.77272725105286\n"
    }
   ],
   "source": [
    "scores = model.evaluate(test_input, test_labels)\n",
    "print(model.metrics_names[1], scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VGG19 for fine-tuning\n",
    "Unfreeze some of the top layer of the convolutional base and train them with the already trained densely connected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_15\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg19 (Model)                (None, 4, 4, 512)         20024384  \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 256)               2097408   \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 3)                 771       \n=================================================================\nTotal params: 22,122,563\nTrainable params: 22,122,563\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Step 1: Combine convolutional base with densely connected network\n",
    "\n",
    "conv_base = VGG19(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 150 validated image filenames belonging to 3 classes.\nFound 20 validated image filenames belonging to 3 classes.\nEpoch 1/5\n15/15 [==============================] - 131s 9s/step - loss: 1.1675 - accuracy: 0.4467\nEpoch 2/5\n15/15 [==============================] - 124s 8s/step - loss: 1.0368 - accuracy: 0.5467\nEpoch 3/5\n15/15 [==============================] - 101s 7s/step - loss: 1.0164 - accuracy: 0.5133\nEpoch 4/5\n15/15 [==============================] - 126s 8s/step - loss: 0.9025 - accuracy: 0.5800\nEpoch 5/5\n15/15 [==============================] - 120s 8s/step - loss: 0.7616 - accuracy: 0.6867\n"
    }
   ],
   "source": [
    "# Step 2: Freeze the convolutional base and train only densely connected network\n",
    "conv_base.trainable = False\n",
    "\n",
    "def get_generator(df, sample_count, batch_size):\n",
    "    return datagen.flow_from_dataframe(dataframe=df.iloc[0:sample_count,:], directory=None, x_col='Full_Path', y_col='Cat',\n",
    "                                       target_size=(150, 150), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "train_generator = get_generator(df_train, 150, 10)\n",
    "test_generator = get_generator(df_test, 20, 2)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=15, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.950821042060852, 0.6818181872367859]"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# Check accuracy \n",
    "model.evaluate_generator(test_generator, steps=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_15\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg19 (Model)                (None, 4, 4, 512)         20024384  \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 256)               2097408   \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 3)                 771       \n=================================================================\nTotal params: 22,122,563\nTrainable params: 2,098,179\nNon-trainable params: 20,024,384\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Step 3: Set trainable attribute of last n layers of convolutional base to True\n",
    "\n",
    "n = 5\n",
    "conv_base.trainable = False \n",
    "for layer in conv_base.layers[-n:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 150 validated image filenames belonging to 3 classes.\nFound 20 validated image filenames belonging to 3 classes.\nEpoch 1/5\n15/15 [==============================] - 134s 9s/step - loss: 0.7884 - accuracy: 0.6733\nEpoch 2/5\n15/15 [==============================] - 125s 8s/step - loss: 0.7286 - accuracy: 0.6867\nEpoch 3/5\n15/15 [==============================] - 121s 8s/step - loss: 0.6631 - accuracy: 0.6933\nEpoch 4/5\n15/15 [==============================] - 111s 7s/step - loss: 0.6255 - accuracy: 0.7400\nEpoch 5/5\n15/15 [==============================] - 112s 7s/step - loss: 0.5949 - accuracy: 0.7200\n"
    }
   ],
   "source": [
    "# Step 4: Train last layers of convolutional base jointly with densely connected layer \n",
    "\n",
    "def get_generator(df, sample_count, batch_size):\n",
    "    return datagen.flow_from_dataframe(dataframe=df.iloc[0:sample_count,:], directory=None, x_col='Full_Path', y_col='Cat',\n",
    "                                       target_size=(150, 150), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "train_generator = get_generator(df_train, 150, 10)\n",
    "test_generator = get_generator(df_test, 20, 2)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=15, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.571797251701355, 0.8636363744735718]"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Check accuracy \n",
    "model.evaluate_generator(test_generator, steps=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitmichaelvirtualenv8c63a04aa4df46b1aed515199121a56c",
   "display_name": "Python 3.7.4 64-bit ('Michael': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}