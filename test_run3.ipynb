{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvBaseSearch\n",
    "\n",
    "All three approaches are following the same structure:\n",
    "\n",
    "### 1. Create an instance of the searcher\n",
    "Give as arguments\n",
    "* a list of strings with the pretrained models you want to test,\n",
    "* the numer of classes of the dataset, \n",
    "* the shape of the input the model will receive  \n",
    "* optionally, a custom top model (if None, a simple 1 Dense, 1 Dropout network is used) and\n",
    "* in ConvBaseSearchWI only, the number of layers that should be fine tuned.\n",
    "\n",
    "\n",
    "### 2. Compile the models\n",
    "Give as arguments\n",
    "* optimizer,\n",
    "* loss function and \n",
    "* list of metrics.\n",
    "\n",
    "\n",
    "### 3. Fit the models\n",
    "Give as arguments\n",
    "* train set generator object \n",
    "* steps per epoch\n",
    "* number of epochs\n",
    "* optionally, validation data and validation steps per epoch\n",
    "* in ConvBaseSearchSFE only, the batch size (in the other classes the batch size of the generator is used).\n",
    "\n",
    "\n",
    "### 4. Evaluate models\n",
    "Give as argument\n",
    "* test set generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/42654961/creating-pandas-dataframe-from-os\n",
    "res = []\n",
    "path = 'C:\\\\Users\\\\Michael\\\\Desktop\\\\Master\\\\Deep Learning\\\\Project\\\\011_Fotos\\\\'\n",
    "#path = 'E:\\\\Dados\\\\FLH HOLIDAY RENTALS\\\\011_Fotos\\\\'\n",
    "for root, dirs, files in os.walk(path, topdown=True):\n",
    "    if len(files) > 0:\n",
    "        res.extend(list(zip([root]*len(files), files)))\n",
    "\n",
    "df = pd.DataFrame(res, columns=['Path', 'File_Name'])\n",
    "\n",
    "df = df[df['File_Name'] != 'Thumbs.db']\n",
    "#df['ClientId'] = df.Path.apply(lambda x: int(x.split(\"\\\\\")[-1]))\n",
    "#df = df[df['ClientId'] < 10000]\n",
    "\n",
    "df['Full_Path'] = df[\"Path\"] + '\\\\' + df[\"File_Name\"]\n",
    "df['Cat'] = df.File_Name.apply(lambda x: x.split(\".\")[0].split(\"_\")[-1])\n",
    "\n",
    "classes = ['1','3','4']\n",
    "df = df[df.Cat.isin(classes)]\n",
    "df_total = df\n",
    "numOfSamplesCat = 30\n",
    "\n",
    "df = pd.DataFrame(columns=df_total.columns)\n",
    "# Get only n pics of each class\n",
    "for cl in classes:\n",
    "    df_class = shuffle(df_total[df_total['Cat'] == cl]).iloc[:numOfSamplesCat, :]\n",
    "    df = df.append(df_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Feature Extraction\n",
    "The convolutional base of the pretrained model is plugged to a custom top model. All layers in the convolutional base are frozen, only the custom top model will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 72 validated image filenames belonging to 3 classes.\nFound 18 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = train_datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transferlearning3 import ConvBaseSearchIFE\n",
    "classifier = ConvBaseSearchIFE(['vgg16','vgg19'], len(classes), input_shape=(64,64,3), top_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting  vgg16\nEpoch 1/1\n2/2 [==============================] - 41s 20s/step - loss: 2.5064 - accuracy: 0.3472 - val_loss: 2.6932 - val_accuracy: 0.1667\nScore on val set:  0.1666666716337204 \n\nFitting  vgg19\nEpoch 1/1\n2/2 [==============================] - 26s 13s/step - loss: 3.2596 - accuracy: 0.2639 - val_loss: 1.8060 - val_accuracy: 0.5000\nScore on val set:  0.5 \n\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs = 1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [2.039909601211548, 0.5], 'vgg19': [1.8895803689956665, 0.5]}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standalone Feature Extraction\n",
    "The feature map produced by the convolutional base of the pretrained model is extracted first and then they are used as the input for tha custom top model. \n",
    "\n",
    "_Faster than integrated feature extraction, but data augmentation techniques cannot be applied to the input data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 72 validated image filenames belonging to 3 classes.\nFound 18 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 50\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transferlearning3 import ConvBaseSearchSFE\n",
    "classifier = ConvBaseSearchSFE(['vgg16','vgg19'], len(classes), input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting Features...\nSuccessfully extraced features from  vgg16\nSuccessfully extraced features from  vgg19\n\nFit top model with feature maps\nFitting  vgg16\nTrain on 72 samples, validate on 18 samples\nEpoch 1/1\n72/72 [==============================] - 1s 10ms/step - loss: 2.0411 - accuracy: 0.2778 - val_loss: 1.1861 - val_accuracy: 0.4444\nScore on val set:  0.4444444477558136\nFitting  vgg19\nTrain on 72 samples, validate on 18 samples\nEpoch 1/1\n72/72 [==============================] - 0s 1ms/step - loss: 1.8396 - accuracy: 0.3472 - val_loss: 1.3662 - val_accuracy: 0.3889\nScore on val set:  0.3888888955116272\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs = 1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "18/18 [==============================] - 0s 222us/step\n18/18 [==============================] - 0s 166us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [0.8843796253204346, 0.3888888955116272],\n 'vgg19': [1.3661738634109497, 0.3888888955116272]}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning\n",
    "The convolutional base of the pretrained model is plugged to a custom top model. The last n_trainable layers of the convolutional base are trained jointly with the custom top model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 72 validated image filenames belonging to 3 classes.\nFound 18 validated image filenames belonging to 3 classes.\n"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "batch_size = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(dataframe=df_train, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = train_datagen.flow_from_dataframe(dataframe=df_test, directory = None, x_col='Full_Path', y_col='Cat',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transferlearning3 import ConvBaseSearchFT\n",
    "classifier = ConvBaseSearchFT(['vgg16','vgg19'], len(classes), input_shape=(64,64,3), n_trainable=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initial training\nFitting  vgg16\nEpoch 1/1\n2/2 [==============================] - 34s 17s/step - loss: 2.0275 - accuracy: 0.3333 - val_loss: 1.7583 - val_accuracy: 0.4444\nScore on val set:  0.4444444477558136 \n\nFitting  vgg19\nEpoch 1/1\n2/2 [==============================] - 25s 12s/step - loss: 2.1676 - accuracy: 0.4722 - val_loss: 1.3882 - val_accuracy: 0.3333\nScore on val set:  0.3333333432674408 \n\nFine tuning of last 5 layers\nFitting  vgg16\nEpoch 1/1\n2/2 [==============================] - 27s 13s/step - loss: 1.3336 - accuracy: 0.4167 - val_loss: 1.3207 - val_accuracy: 0.4444\nScore on val set:  0.4444444477558136 \n\nFitting  vgg19\nEpoch 1/1\n2/2 [==============================] - 36s 18s/step - loss: 1.3701 - accuracy: 0.5278 - val_loss: 1.2481 - val_accuracy: 0.3889\nScore on val set:  0.3888888955116272 \n\n"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = df_train.shape[0] // batch_size + 1,\n",
    "                         epochs = 1, validation_data = test_set,  validation_steps = df_test.shape[0] // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'vgg16': [1.4940133094787598, 0.3888888955116272],\n 'vgg19': [1.387073278427124, 0.3888888955116272]}"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "classifier.evaluate_generator(test_set)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitmichaelvirtualenv8c63a04aa4df46b1aed515199121a56c",
   "display_name": "Python 3.7.4 64-bit ('Michael': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}